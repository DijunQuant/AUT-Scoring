{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ew_multiplied_vector(phrase_list, sem_space):\n",
    "    vectors_list = []\n",
    "    # add vectors to list\n",
    "    # change to numpy array\n",
    "    for term in phrase_list:\n",
    "        try:\n",
    "            vectors_list.append(np.array(sem_space.loc[term].values.tolist()))\n",
    "        except:\n",
    "            print('cannot find '+term)\n",
    "    # get element wise multiplied vector\n",
    "    if len(vectors_list)==0: return np.nan\n",
    "    element_wise_multiplied_vector = np.ones(len(sem_space.columns))\n",
    "    # calculate element wise multiplied vector\n",
    "    for vector in vectors_list:\n",
    "        element_wise_multiplied_vector = element_wise_multiplied_vector * vector\n",
    "\n",
    "    # return element wise multiplied vector\n",
    "    return element_wise_multiplied_vector\n",
    "def lemmatize(text, stopwords_list):\n",
    "    # replace symbols with spaces\n",
    "    text = re.sub(\"/|-\", \" \", text)\n",
    "\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # tokenize the phrase\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # lowercase all tokens\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "\n",
    "    # remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords_list]\n",
    "\n",
    "    # lemmatize words if needed\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "#compute centroid of the list of vectors, as the average of the normalized vectors\n",
    "def calc_centroid(vector_list):\n",
    "    vector_len=len(vector_list[0]) #the length of the embedded vector\n",
    "    centroid=np.zeros(vector_len)\n",
    "    for v in vector_list:\n",
    "        centroid=centroid+v/np.linalg.norm(v)\n",
    "    centroid=centroid/len(vector_list)\n",
    "    return centroid\n",
    "def get_cosine_distance(feature_vec_1, feature_vec_2):\n",
    "    return (1 - cosine_similarity(feature_vec_1.reshape(1, -1), feature_vec_2.reshape(1, -1))[0][0])\n",
    "\n",
    "\n",
    "#main function to compute the diversity metric, input is the responses from same participant for a single prompt\n",
    "#each response is already converted to embedded vectors using certain composition\n",
    "def calc_diversity(vector_list):\n",
    "    centroid=calc_centroid(vector_list)\n",
    "    dist=[]\n",
    "    for v in vector_list:\n",
    "        dist.append(get_cosine_distance(centroid,v))\n",
    "    #return the max of all distance, root mean square of the distance\n",
    "    #they are equivalent in some sense, root mean squre might behave sligthly better as the diversity metric\n",
    "    return np.max(dist),np.sqrt(np.mean(np.array(dist)**2))\n",
    "\n",
    "\n",
    "def dispersion_vectors(responses,sp):\n",
    "    if len(responses)<2:\n",
    "        return np.nan,np.nan\n",
    "    response_vector = [get_ew_multiplied_vector(x, sp) for x in responses]\n",
    "    response_vector = [x for x in response_vector if type(x)!=float]\n",
    "    return calc_diversity(response_vector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load semantic space to a dictionary\n",
    "# Load stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='/Users/yyu/Box Sync/ORG-SCHOOL-WCAS-PSYCHOLOGY-BEEMAN-LAB/COAT/scoring/'\n",
    "sp='cbow_6_ukwac_subtitle'\n",
    "semspace_dict={}\n",
    "semspace_dict[sp] = pd.read_csv(folder+'/semantic_spaces/'+sp+'.txt', delimiter = \" \", header = None).set_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_edited = list(STOP_WORDS)\n",
    "stopwords_edited.append(\"thing\")\n",
    "stopwords_edited.append(\"use\")\n",
    "stopwords_edited.append(\"things\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dispersion Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'table'\n",
    "responses = ['stand on top to dance','block door','burn it']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['stand', 'dance'], ['block', 'door'], ['burn']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_vec = [lemmatize(r,stopwords_edited) for r in responses]\n",
    "responses_vec = [[w for w in r if w!=prompt] for r in responses_vec]\n",
    "responses_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4248608392207669, 0.38370818514983984)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#two output here, mostly equivalanet, second is better\n",
    "dispersion_vectors(responses_vec,semspace_dict[sp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
