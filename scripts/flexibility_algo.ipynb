{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexibility Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Flexibility Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from functools import reduce\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.lm import NgramCounter\n",
    "import string\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Data from Excel Sheet into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual df's for each sheet\n",
    "\n",
    "# when on pc\n",
    "data_test_cup = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_cup_semdis.csv\")\n",
    "data_test_key = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_key_semdis.csv\")\n",
    "data_test_rope = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_rope_semdis.csv\")\n",
    "data_test_brick = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_brick_semdis.csv\")\n",
    "data_test_chair = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_chair_semdis.csv\")\n",
    "data_test_pencil = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_pencil_semdis.csv\")\n",
    "data_test_shoe = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_shoe_semdis.csv\")\n",
    "\n",
    "# when on mac\n",
    "# data_test_cup = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_cup_semdis.csv.xlsx\")\n",
    "# data_test_key = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_key_semdis.csv.xlsx\")\n",
    "# data_test_rope = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_rope_semdis.csv.xlsx\")\n",
    "# data_test_brick = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_brick_semdis.csv.xlsx\")\n",
    "# data_test_chair = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_chair_semdis.csv.xlsx\")\n",
    "# data_test_pencil = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_pencil_semdis.csv.xlsx\")\n",
    "# data_test_shoe = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/test/semdis/autdata_test_shoe_semdis.csv.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk corpus stop words\n",
    "stopwords_nltk = stopwords.words('english')\n",
    "# spacy stop words\n",
    "stopwords_spacy = STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_edited = list(stopwords_spacy)\n",
    "stopwords_edited.append(\"thing\")\n",
    "stopwords_edited.append(\"things\")\n",
    "stopwords_edited.append(\"use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to clean the responses\n",
    "def process_text(text, stopwords_list, remove_sw, join_list):\n",
    "    # tokenize text, lemmanize words, removing punctuation, remove stop words, lowercase all words\n",
    "\n",
    "    # hardcorded for special situations\n",
    "    text = re.sub(\"wedging\",\"wedge\", text)\n",
    "    text = re.sub(\"exersizing\",\"exercising\", text)\n",
    "    text = re.sub(\"thrown\",\"throw\", text)\n",
    "    \n",
    "    text = re.sub(\"/|-\",\" \", text)\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    if remove_sw:\n",
    "        tokens = [word for word in tokens if word not in stopwords_list]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "#         stemmer = PorterStemmer()\n",
    "#         tokens = [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    if join_list:\n",
    "        tokens = ' '.join(tokens)\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get a list of participants\n",
    "def get_id_list(df):\n",
    "    id_list = df['id'].unique()\n",
    "    id_list = sorted(id_list)\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to add a new column\n",
    "# new column are cleaned responses\n",
    "def get_cleaned_responses(df, stopwords_list, remove_sw, join_list):\n",
    "    # id_df = df[df.id == id]\n",
    "    df_processed = df.copy(deep=True)\n",
    "    responses = df['response'].tolist()\n",
    "\n",
    "    # make list of processed responses\n",
    "    for response in range(len(responses)):\n",
    "        responses[response] = process_text(responses[response], stopwords_list, remove_sw, join_list)\n",
    "\n",
    "    # add list as column in df\n",
    "    df_processed['response_processed'] = responses\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility Algo 1\n",
    "### tf-idf scikit-learn + clustering\n",
    "### ___ as document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_vector(num_clusters, responses):\n",
    "    # initialize CountVectorizer object\n",
    "    tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "    # vectorize the phrases\n",
    "    tfidf = tfidf_vectorizer.fit_transform(responses)\n",
    "    \n",
    "    # elbow method to visualize and find out how many clusters to use\n",
    "#     visualizer = KElbowVisualizer(KMeans(), k=(1,12), timings=False)\n",
    "#     visualizer.fit(tfidf.toarray())       \n",
    "#     visualizer.show()\n",
    "\n",
    "    # nltk kmeans cosine distance implementation\n",
    "    number_of_clusters = num_clusters\n",
    "    kmeans = KMeansClusterer(number_of_clusters, repeats=25, distance=nltk.cluster.util.cosine_distance, avoid_empty_clusters=True)\n",
    "#     print(\"over here\")\n",
    "    assigned_clusters = kmeans.cluster(tfidf.toarray(), assign_clusters=True)\n",
    "#     print(\"HERE\")\n",
    "#     scikit-learn euclidean distance implementation\n",
    "#     kmeans = KMeans(n_clusters = num_clusters).fit(tfidf)\n",
    "        \n",
    "    # cluster results scikit-learn\n",
    "    results = pd.DataFrame()\n",
    "    results['text'] = responses\n",
    "#     results['category'] = kmeans.labels_\n",
    "    results['category'] = assigned_clusters\n",
    "    \n",
    "    # create dictionary to organize the clusters with their respective phrases\n",
    "    results_dict = {k: g[\"text\"].tolist() for k,g in results.groupby(\"category\")}\n",
    "    \n",
    "    # df of the clusters and the \n",
    "    clusters_df = pd.DataFrame(list(results_dict.items()),columns = ['category','responses']) \n",
    "    \n",
    "    # uncomment to see clusters \n",
    "#     print(results_dict)\n",
    "#     display(clusters_df)\n",
    "    \n",
    "    return clusters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flexibility_score(flexibility_rating_df, num_clusters, responses):\n",
    "    clusters_df = get_tfidf_vector(num_clusters, responses)\n",
    "    \n",
    "    # create dictionary out of cluster df\n",
    "    # has clusters and their respective responses\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "    \n",
    "    flex_df_cleaned = flexibility_rating_df[flexibility_rating_df.response_processed != '']\n",
    "    participants = get_id_list(flexibility_rating_df)\n",
    "    participants_responses_list = list(zip(flex_df_cleaned.id, flex_df_cleaned.response_processed))\n",
    "    \n",
    "    # get dictionary of each participants responses\n",
    "    participants_responses_dict = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_responses_dict[participants_responses_list[index][0]].append(participants_responses_list[index][1])\n",
    "        \n",
    "    # get dictionary of responses and their respective dictionary\n",
    "    responses_cluster_rep = {}\n",
    "    \n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            responses_cluster_rep[phrase] = key\n",
    "            \n",
    "    # get dictionary of participants and clusters their responses existed in\n",
    "    participants_clusters_apperance = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_clusters_apperance[participants_responses_list[index][0]].append(responses_cluster_rep[participants_responses_list[index][1]])\n",
    "        \n",
    "    # get dic of number of clusters a participants responses are in\n",
    "    \n",
    "    participants_clusters_seen = {k: [] for k in participants}\n",
    "    \n",
    "    for participant in participants_clusters_seen:\n",
    "        responses_set = set(participants_clusters_apperance[participant])\n",
    "        participants_clusters_seen[participant] = len(responses_set)\n",
    "    \n",
    "#     print(clusters)\n",
    "#     print()\n",
    "#     print(participants_responses_list)\n",
    "#     print()\n",
    "#     print(participants_responses_dict)\n",
    "#     print()\n",
    "#     print(responses_cluster_rep)\n",
    "#     print()\n",
    "#     print(participants_clusters_apperance)\n",
    "#     print()\n",
    "#     print(participants_clusters_seen)\n",
    "    \n",
    "    flexibility_df = pd.DataFrame(participants_clusters_seen.items(), columns=['id', 'flexibility'])\n",
    "    return flexibility_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flexibility_tfidf_scikit_learn_clustering(df, stopwords_list, num_clusters, remove_sw, join_list):\n",
    "    flexibility_rating_df = get_cleaned_responses(df, stopwords_list, remove_sw, join_list)\n",
    "    responses_split = flexibility_rating_df['response_processed'].tolist()\n",
    "    responses_split = [word for word in responses_split if word != '']\n",
    "    flexibility_rating_df = flexibility_rating_df[flexibility_rating_df.astype(str)['response_processed'] != '']\n",
    "    responses = []\n",
    "    \n",
    "    id_list = get_id_list(df)\n",
    "    \n",
    "    for participant in id_list:\n",
    "        temp_df = flexibility_rating_df.loc[flexibility_rating_df['id'] == participant]\n",
    "        temp_list = temp_df['response_processed'].tolist()\n",
    "        temp_list = ' '.join(temp_list)\n",
    "        responses.append(temp_list)\n",
    "                \n",
    "    flexibility_rating_df = get_flexibility_score(flexibility_rating_df, num_clusters, responses_split)\n",
    "        \n",
    "    return flexibility_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1093</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1603</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1610</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1622</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  flexibility\n",
       "0   1087            2\n",
       "1   1093            3\n",
       "2   1094            4\n",
       "3   1102            3\n",
       "4   1104            2\n",
       "..   ...          ...\n",
       "84  1603            3\n",
       "85  1610            3\n",
       "86  1614            2\n",
       "87  1621            2\n",
       "88  1622            4\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flexibility_tfidf_scikit_learn_clustering(data_official_brick, stopwords_edited, 15, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Algo Results with Human Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when on pc\n",
    "data_official_cup = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Cup')\n",
    "data_official_key = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Key')\n",
    "data_official_rope = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Rope')\n",
    "data_official_brick = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Brick')\n",
    "data_official_chair = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Chair')\n",
    "data_official_pencil = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Pencil')\n",
    "data_official_shoe = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Shoe')\n",
    "data_official_box = pd.read_excel(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results_cleaned.xlsx\", sheet_name='Box')\n",
    "\n",
    "# # when on mac\n",
    "# # data_official_cup = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Cup')\n",
    "# # data_official_key = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Key')\n",
    "# # data_official_rope = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Rope')\n",
    "# # data_official_brick = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Brick')\n",
    "# # data_official_chair = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Chair')\n",
    "# # data_official_pencil = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Pencil')\n",
    "# # data_official_shoe = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Shoe')\n",
    "# # data_official_box = pd.read_excel(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/flexibility/official/autdata_flex_results.xlsx\", sheet_name='Box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_list = ['box', 'brick', 'chair', 'cup', 'key', 'pencil', 'rope', 'shoe']\n",
    "data_list = [data_official_box, data_official_brick, data_official_chair, data_official_cup, data_official_key, data_official_pencil, data_official_rope, data_official_shoe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_list)):\n",
    "    print(prompts_list[i])\n",
    "    data_list[i]['flexibility_m'] = data_list[i][['flexibility_1', 'flexibility_2']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_flexibility_corrs():\n",
    "    flexibility_df_list = []\n",
    "    for i in range(len(prompts_list)):\n",
    "        print(prompts_list[i])\n",
    "        id_list = get_id_list(data_list[i])\n",
    "        participants_clusters_seen = {k: 0 for k in id_list}\n",
    "        for participant in participants_clusters_seen:\n",
    "            id_df = data_list[i][data_list[i].id == participant]\n",
    "            cluster_apperance = len(id_df['flexibility_m'].unique())\n",
    "            participants_clusters_seen[participant] = cluster_apperance\n",
    "        flexibility_df_rater = pd.DataFrame(participants_clusters_seen.items(), columns=['id', 'rating'])\n",
    "        flexibility_df_method = get_flexibility_tfidf_scikit_learn_clustering(data_list[i], stopwords_edited, 15, True, True)\n",
    "        df_cd = pd.merge(flexibility_df_rater, flexibility_df_method, how='inner', on = 'id')\n",
    "        flexibility_df_list.append(df_cd)\n",
    "        \n",
    "    return flexibility_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n"
     ]
    }
   ],
   "source": [
    "flex_results_list = print_flexibility_corrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1093</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1599</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1603</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1610</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1614</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1621</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  rating  flexibility\n",
       "0   1087       3            1\n",
       "1   1093       2            3\n",
       "2   1094       2            2\n",
       "3   1102       3            3\n",
       "4   1104       1            2\n",
       "..   ...     ...          ...\n",
       "84  1599       1            2\n",
       "85  1603       2            3\n",
       "86  1610       2            5\n",
       "87  1614       2            1\n",
       "88  1621       1            2\n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flex_results_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12870684649520894, 0.22934023716749752)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.pearsonr(flex_results_list[0]['rating'], flex_results_list[0]['flexibility'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_flexiblity_results(results):\n",
    "    corrs_tuple_list = []\n",
    "    for i in range(len(prompts_list)):\n",
    "        corrs_tuple_list.append(stats.pearsonr(results[i]['rating'], results[i]['flexibility']))\n",
    "        \n",
    "    result_df = pd.DataFrame(corrs_tuple_list, columns=['corrs', 'pval'])\n",
    "    \n",
    "    result_df.index = prompts_list\n",
    "    \n",
    "    writer = pd.ExcelWriter('flexibility_methods_results_071321.xlsx', engine='xlsxwriter')\n",
    "    result_df.to_excel(writer, startrow = 0, startcol=0)\n",
    "    writer.save()\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_flexibility_results(results):\n",
    "    writer = pd.ExcelWriter('flexibility_methods_results_071321_5times.xlsx', engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "\n",
    "    col = 0\n",
    "    for y in range(5):\n",
    "        print(y)\n",
    "        corrs_tuple_list = []\n",
    "        results = print_flexibility_corrs()\n",
    "        for i in range(len(prompts_list)):\n",
    "            corrs_tuple_list.append(stats.pearsonr(results[i]['rating'], results[i]['flexibility']))\n",
    "\n",
    "        result_df = pd.DataFrame(corrs_tuple_list, columns=['corrs', 'pval'])\n",
    "\n",
    "        result_df.index = prompts_list\n",
    "\n",
    "        result_df.to_excel(writer, startrow = 0, startcol= col)\n",
    "        col = col + len(result_df.columns) + 3\n",
    "        print(\"written\")\n",
    "            \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corrs</th>\n",
       "      <th>pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>box</th>\n",
       "      <td>0.128707</td>\n",
       "      <td>0.229340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brick</th>\n",
       "      <td>0.274407</td>\n",
       "      <td>0.009260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chair</th>\n",
       "      <td>0.200706</td>\n",
       "      <td>0.057855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cup</th>\n",
       "      <td>0.133710</td>\n",
       "      <td>0.211592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>0.234814</td>\n",
       "      <td>0.025898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pencil</th>\n",
       "      <td>0.342354</td>\n",
       "      <td>0.000957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rope</th>\n",
       "      <td>0.187489</td>\n",
       "      <td>0.076804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shoe</th>\n",
       "      <td>0.191067</td>\n",
       "      <td>0.071240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           corrs      pval\n",
       "box     0.128707  0.229340\n",
       "brick   0.274407  0.009260\n",
       "chair   0.200706  0.057855\n",
       "cup     0.133710  0.211592\n",
       "key     0.234814  0.025898\n",
       "pencil  0.342354  0.000957\n",
       "rope    0.187489  0.076804\n",
       "shoe    0.191067  0.071240"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheesh = calculate_flexiblity_results(flex_results_list)\n",
    "sheesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n",
      "written\n",
      "1\n",
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n",
      "written\n",
      "2\n",
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n",
      "written\n",
      "3\n",
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n",
      "written\n",
      "4\n",
      "box\n",
      "brick\n",
      "chair\n",
      "cup\n",
      "key\n",
      "pencil\n",
      "rope\n",
      "shoe\n",
      "written\n"
     ]
    }
   ],
   "source": [
    "# write_flexibility_results(flex_results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo Design Brainstorming:\n",
    "\n",
    "To Do List\n",
    "- [ ] brainstorm strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
