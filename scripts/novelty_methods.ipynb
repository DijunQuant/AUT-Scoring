{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novelty Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Novelty Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "import shared_functions as sf\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Spaces\n",
    "### Word2Vec Models for Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model\n",
    "word_model_twitter25 = api.load(\"glove-twitter-25\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of counts for each word in model\n",
    "twitter25_dict = {}\n",
    "for i in range(len(word_model_twitter25)):\n",
    "    twitter25_dict[word_model_twitter25.index_to_key[i]] = word_model_twitter25.key_to_index[word_model_twitter25.index_to_key[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the frequency of each word in dictionary\n",
    "total_words = 0\n",
    "for key in twitter25_dict:\n",
    "    total_words = total_words + twitter25_dict[key]\n",
    "    \n",
    "for key in twitter25_dict:\n",
    "    twitter25_dict[key] = twitter25_dict[key]/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 1\n",
    "### Avg Distance using Word2Vec\n",
    "### Lesser Average Similarity, More Novel\n",
    "### More of a Proof of Concept Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get the novelty rating\n",
    "# average of the similarities seen\n",
    "def get_similarity_word2vec_avg(prompt, phrase_list, word_model):\n",
    "    avg_sim = 0\n",
    "    # find similarity of each word in phrase with the prompt\n",
    "    for term in range(len(phrase_list)):\n",
    "        avg_sim = avg_sim + word_model.similarity(w1 = prompt, w2 = phrase_list[term])\n",
    "        \n",
    "    # take the average\n",
    "    if len(phrase_list) == 0:\n",
    "        avg_sim = 0\n",
    "    else:\n",
    "        avg_sim = avg_sim/len(phrase_list)\n",
    "        \n",
    "    return (avg_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method that returns the dataframe with novelty rating for each phrase\n",
    "def get_novelty_word2vec_avg(df, prompt, stopwords_list, word_model, join_list):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # list to keep parallel list of the responses similarity\n",
    "    avg_sim_list = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        avg_sim_list.append(get_similarity_word2vec_avg(prompt, response, word_model))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['avg_sim'] = avg_sim_list\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 2\n",
    "### Word2Vec + Smooth Inverse Frequency + Cosine Similarity\n",
    "\n",
    "### Does work well because phrases are super short\n",
    "### Don't use\n",
    "### Fix if have time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to apply SIF to the vectors \n",
    "def get_sif_feature_vectors(prompt, response, word_model):\n",
    "    # set the word count dictionary with frequencies\n",
    "    word_counts = twitter25_dict\n",
    "    # size of vectore in word embeddings\n",
    "    embedding_size = 25 \n",
    "    # set hyper parameter\n",
    "    a = 0.001\n",
    "    # list to store vectors\n",
    "    phrase_set = []\n",
    "    for phrase in [prompt, response]:\n",
    "        # zero out the vector\n",
    "        vs = np.zeros(embedding_size)\n",
    "        phrase_length = len(phrase)\n",
    "        for word in phrase:\n",
    "            # smooth inverse frequency, SIF\n",
    "            a_value = a / (a + word_counts[word]) \n",
    "            # vs += sif * word_vector\n",
    "            vs = np.add(vs, np.multiply(a_value, word_model[word]))\n",
    "        # weighted average\n",
    "        if phrase_length == 0:\n",
    "            vs[:] = 0\n",
    "        else:\n",
    "            vs = np.divide(vs, phrase_length) \n",
    "        phrase_set.append(vs)\n",
    "    # return the SIF adjusted vectors\n",
    "    return phrase_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_word2vec_sif(prompt, response, word_model):\n",
    "    # get the SIF adjusted vectors\n",
    "    vectors = get_sif_feature_vectors(prompt, response, word_model)\n",
    "    # return the cosine similarity\n",
    "    return (sf.get_cosine_distance(vectors[0], vectors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_novelty_word2vec_sif(df, prompt, stopwords_list, word_model, join_list):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # list to keep parallel list of the responses similarity\n",
    "    avg_sim_list = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        avg_sim_list.append(get_similarity_word2vec_sif_cosinesim(prompt, response, word_model))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['SIF + cosine sim'] = avg_sim_list\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 3\n",
    "### sem_space + element wise multiplication + cosine distance\n",
    "### Greater Cos Distance, Greater Novelty\n",
    "### Most similar to SemDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get the element wise multiplied vector\n",
    "# multiply vectors in phrase\n",
    "def get_ew_multiplied_vector(phrase_list, sem_space):\n",
    "    vectors_list = []\n",
    "    # add vectors to list\n",
    "    # change to numpy array\n",
    "    for term in phrase_list:\n",
    "        vectors_list.append(np.array(sem_space.loc[term].values.tolist()))\n",
    "    \n",
    "    # get element wise multiplied vector\n",
    "    element_wise_multiplied_vector = np.ones(len(sem_space.columns))\n",
    "\n",
    "    # calculate element wise multiplied vector\n",
    "    for vector in vectors_list:\n",
    "        element_wise_multiplied_vector = element_wise_multiplied_vector * vector\n",
    "\n",
    "    # return element wise multiplied vector\n",
    "    return element_wise_multiplied_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cosine sim from prompt and ewm\n",
    "def get_ewm_cosdist(prompt, response, sem_space):\n",
    "    # get prompt vector and ewm vector using semantic space\n",
    "    prompt_vector = np.array(sem_space.loc[prompt].values.tolist())\n",
    "    ewm_vector = get_ew_multiplied_vector(response, sem_space)\n",
    "\n",
    "    # return cosine dist between prompt and ewm\n",
    "    return (sf.get_cosine_distance(prompt_vector, ewm_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df with results of the cosine distance from prompt using the elementwise multiplied vectors in the response\n",
    "def get_novelty_ewm(df, prompt, stopwords_list, sem_space, join_list):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # list to store cosine sims\n",
    "    cosine_sim_list = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        cosine_sim_list.append(get_ewm_cosdist(prompt, response, sem_space))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['ewm_vector_cosine_dis'] = cosine_sim_list\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 4\n",
    "### sem_space + local minina + cosine distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word in phrase that has the least distance from the prompt\n",
    "def get_minvec(prompt, phrase_list, sem_space):\n",
    "    distances_list = []\n",
    "    # get prompt vector\n",
    "    prompt_vector = np.array(sem_space.loc[prompt].values.tolist())\n",
    "    \n",
    "    # create list of cosine distances\n",
    "    for term in phrase_list:\n",
    "        distances_list.append(sf.get_cosine_distance(prompt_vector, np.array(sem_space.loc[term].values.tolist())))\n",
    "        \n",
    "    # return the max cosine distance\n",
    "    return max(distances_list, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df with results of the cosine distance from prompt using the minima vector in the response\n",
    "def get_novelty_minvec(df, prompt, stopwords_list, sem_space, join_list):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # list to store cosine sims\n",
    "    cosine_sim_list = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        cosine_sim_list.append(get_minvec(prompt, response, sem_space))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['minima_vector_cosine_dis'] = cosine_sim_list\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 5\n",
    "### element wise multiplication + cosine distance + clustering\n",
    "### average responses cosine distance in the same cluster\n",
    "### idea is that phrases with same alternate task will group\n",
    "### variation in phrase in the same cluster will  be averaged out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages the distance of the phrases in each cluster\n",
    "# gives each phrase in cluster the average distance \n",
    "def get_clustered_novelty_score(novel_rating_df, column, num_clusters, display_clusters):\n",
    "    # get cluster df\n",
    "    clusters_df = sf.get_counts_vector(num_clusters, novel_rating_df['response_processed_phrase'].tolist(), display_clusters)\n",
    "    # get cleaned phrases and their current novelty rating\n",
    "    novelty_scores = dict(zip(novel_rating_df.response_processed_phrase, novel_rating_df[column]))\n",
    "\n",
    "    # create dictionary out of cluster df\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "        \n",
    "    # initialize empty dictionary to store the score for a category\n",
    "    clusters_scores = dict.fromkeys(clusters)\n",
    "    \n",
    "    # get the average cosine distance for a cluster\n",
    "    for key in clusters:\n",
    "        # find total of distance of terms in phrase\n",
    "        score = 0\n",
    "        for phrase in clusters[key]:\n",
    "            score = score + novelty_scores[phrase]\n",
    "        # find the average\n",
    "        score = score/len(clusters[key])\n",
    "        # store cluster score in dictionary\n",
    "        clusters_scores[key] = score\n",
    "        \n",
    "    # create dictionary to store a phrase and its new novelty score \n",
    "    # new score is the average of the responses in one cluster\n",
    "    phrase_scores_dict = {}\n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            phrase_scores_dict[phrase] = clusters_scores[key]\n",
    "            \n",
    "    # make a list that matches the one in the current dataframe\n",
    "    # return list to be added to dataframe\n",
    "    df_phrases_scores_list = [] \n",
    "    for phrase in novel_rating_df['response_processed_phrase'].tolist():\n",
    "        df_phrases_scores_list.append(phrase_scores_dict[phrase])\n",
    "\n",
    "    return list(df_phrases_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df with results of the cosine distance from prompt using the elementwise multiplied vectors in the response\n",
    "def get_novelty_ewm_cluster(df, prompt, stopwords_list, sem_space, join_list, num_clusters, display_clusters):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # add column for complete phrase\n",
    "    novel_rating_df['response_processed_phrase'] = [' '.join(x) for x in cleaned_responses]\n",
    "    # list to store cosine sims\n",
    "    cosine_sim_list = []\n",
    "    \n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        print(response)\n",
    "        cosine_sim_list.append(get_ewm_cosdist(prompt, response, sem_space))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['ewm_vector_cosine_dis'] = cosine_sim_list\n",
    "    \n",
    "    # add novelty rating for the average rating of a cluster\n",
    "    novel_rating_df['ewm_vector_cosine_dis_clus_avg'] = get_clustered_novelty_score(novel_rating_df, 'ewm_vector_cosine_dis', num_clusters, display_clusters)\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 6\n",
    "### sem_space + local minima + cosine distance + clustering\n",
    "### average responses cosine distance in the same cluster\n",
    "### idea is that phrases with same alternate task will group\n",
    "### variation in phrase in the same cluster will  be averaged out\n",
    "### differs from algo 5, does local minima not ewm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df with results of the cosine distance from prompt using the elementwise multiplied vectors in the response\n",
    "def get_novelty_minvec_cluster(df, prompt, stopwords_list, sem_space, join_list, num_clusters, display_clusters):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # add column for complete phrase\n",
    "    novel_rating_df['response_processed_phrase'] = [' '.join(x) for x in cleaned_responses]\n",
    "    # list to store cosine sims\n",
    "    cosine_sim_list = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        cosine_sim_list.append(get_minvec(prompt, response, sem_space))\n",
    "\n",
    "    # add novelty rating list to dataframe\n",
    "    novel_rating_df['minima_vector_cosine_dis'] = cosine_sim_list\n",
    "        \n",
    "    # add novelty rating for the average rating of a cluster\n",
    "    novel_rating_df['minima_vector_cosine_dis_clus_avg'] = get_clustered_novelty_score(novel_rating_df, 'minima_vector_cosine_dis', num_clusters, display_clusters)\n",
    "    \n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novelty Algo 7\n",
    "### uses the cosine + minima + clustering methods\n",
    "### uses the same clusterr for all algos\n",
    "### two different scoring systems, average or minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averages the distance of the phrases in each cluster\n",
    "# gives each phrase in cluster the average distance\n",
    "# generalized to avg or min, both ewm and minima\n",
    "def get_clustered_novelty_score_generalized(clusters_df, novel_rating_df, average, column):\n",
    "    # get cleaned phrases and their current novelty rating\n",
    "    novelty_scores = dict(zip(novel_rating_df.response_processed_phrase, novel_rating_df[column]))\n",
    "\n",
    "    # create dictionary out of cluster df\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "        \n",
    "    # initialize empty dictionary to store the score for a category\n",
    "    clusters_scores = dict.fromkeys(clusters)\n",
    "    \n",
    "    # get the average or min cosine distance for a cluster\n",
    "    # calculate average\n",
    "    if average:\n",
    "        for key in clusters:\n",
    "            # keep track of total of distances\n",
    "            score = 0\n",
    "            for phrase in clusters[key]:\n",
    "                score = score + novelty_scores[phrase]\n",
    "            # calculate the average\n",
    "            score = score/len(clusters[key])\n",
    "            # store average distance for the cluster\n",
    "            clusters_scores[key] = score\n",
    "    # find minimum distance\n",
    "    else:\n",
    "        for key in clusters:\n",
    "            scores_list = []\n",
    "            # find the cosine distances of phrases in a cluster\n",
    "            for phrase in clusters[key]:\n",
    "                scores_list.append(novelty_scores[phrase])\n",
    "            # store minimum distance as score for the clusterr\n",
    "            clusters_scores[key] = min(scores_list)\n",
    "        \n",
    "    # create dictionary to store a phrase and its new novelty score \n",
    "    # new score is the average of the responses in one cluster\n",
    "    phrase_scores_dict = {}\n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            phrase_scores_dict[phrase] = clusters_scores[key]\n",
    "            \n",
    "    # make a list that matches the one in the current dataframe\n",
    "    # return list to be added to dataframe\n",
    "    df_phrases_scores_list = [] \n",
    "    for phrase in novel_rating_df['response_processed_phrase'].tolist():\n",
    "        df_phrases_scores_list.append(phrase_scores_dict[phrase])\n",
    "    \n",
    "    # uncomment to show clusters df\n",
    "#     display(clusters_df)\n",
    "            \n",
    "    # return scores list thats parallel to the responses column\n",
    "    return list(df_phrases_scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df with results of the cosine distance from prompt using the elementwise multiplied vectors in the response\n",
    "def get_novelty_combined(df, prompt, stopwords_list, sem_space, join_list, num_clusters, display_clusters):\n",
    "    # clean the responses\n",
    "    novel_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    cleaned_responses = novel_rating_df['response_processed'].tolist()\n",
    "    # store combined phrases as a new column\n",
    "    novel_rating_df['response_processed_phrase'] = [' '.join(x) for x in cleaned_responses]\n",
    "    # list to store cosine sims for ewm\n",
    "    cosine_sim_list_ewm = []\n",
    "    # list to store cosine sims for minima\n",
    "    cosine_sim_list_minima = []\n",
    "\n",
    "    # implement algo\n",
    "    # pass in clean responses\n",
    "    for response in cleaned_responses:\n",
    "        # add novelty rating to list \n",
    "        cosine_sim_list_ewm.append(get_ewm_cosdist(prompt, response, sem_space))\n",
    "        cosine_sim_list_minima.append(get_minvec(prompt, response, sem_space))\n",
    "        \n",
    "     # get clusters for the dataset\n",
    "    # idea is to use the same clusters for each analysis\n",
    "    clusters_df = sf.get_counts_vector(num_clusters, novel_rating_df['response_processed_phrase'].tolist(), display_clusters)\n",
    "\n",
    "    # add novelty rating list to dataframe for ewm\n",
    "    novel_rating_df['ewm_vector_cosine_dis'] = cosine_sim_list_ewm\n",
    "    \n",
    "    # add the columns for the novelty scores\n",
    "    novel_rating_df['ewm_vector_cosine_dis_clus_avg'] = get_clustered_novelty_score_generalized(clusters_df, novel_rating_df, True, 'ewm_vector_cosine_dis')\n",
    "\n",
    "    # add novelty rating list to dataframe for minima\n",
    "    novel_rating_df['minima_vector_cosine_dis'] = cosine_sim_list_minima\n",
    "    novel_rating_df['minima_vector_cosine_dis_clus_avg'] = get_clustered_novelty_score_generalized(clusters_df, novel_rating_df, True, 'minima_vector_cosine_dis')\n",
    "    novel_rating_df['minima_vector_cosine_dis_clus_min'] = get_clustered_novelty_score_generalized(clusters_df, novel_rating_df, False, 'minima_vector_cosine_dis')\n",
    "\n",
    "    # new column with novelty rating\n",
    "    return novel_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Novelty Results into CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "underscore = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_novelty_results(data_dict, semspace_dict, num_clusters):\n",
    "    # create list for the different prompts and semantic spaces\n",
    "    # iterate through each combination of prompt and semantic space\n",
    "    data_keys = list(data_dict.keys())\n",
    "    semspace_keys = list(semspace_dict.keys())\n",
    "    for semspace in semspace_keys:\n",
    "        for data in data_keys:\n",
    "            # get the results df for the corresponding combination of prompt and semantic space\n",
    "            df = get_novelty_combined(data_dict[data], data, stopwords_edited, semspace_dict[semspace], False, num_clusters, False)\n",
    "            df['novelty_m'] = df[['novelty_1', 'novelty_2']].mean(axis=1)\n",
    "            # reorder cols the way I want them \n",
    "            df = df[['id',\n",
    "                 'response',\n",
    "                 'response_nofill',\n",
    "                 'response_processed',\n",
    "                 'response_processed_phrase',\n",
    "                 'item',\n",
    "                 'item_nofill',\n",
    "                 'SemDis_factor',\n",
    "                 'SemDis_cbowukwacsubtitle_nf_m',\n",
    "                 'SemDis_cbowsubtitle_nf_m',\n",
    "                 'SemDis_cbowBNCwikiukwac_nf_m',\n",
    "                 'SemDis_TASA_nf_m',\n",
    "                 'SemDis_glove_nf_m',\n",
    "                 'SemDis_MEAN',\n",
    "                 'ewm_vector_cosine_dis',\n",
    "                 'ewm_vector_cosine_dis_clus_avg',\n",
    "                 'minima_vector_cosine_dis',\n",
    "                 'minima_vector_cosine_dis_clus_avg',\n",
    "                 'minima_vector_cosine_dis_clus_min',\n",
    "                 'novelty_1',\n",
    "                 'novelty_2',\n",
    "                 'novelty_m']]\n",
    "            # write results table into csv\n",
    "            df.to_csv(data + underscore + semspace + underscore + \"results\" + \".csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
