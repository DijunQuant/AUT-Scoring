{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexibility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Flexibility Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "import shared_functions as sf\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility Algo \n",
    "### tf-idf scikit-learn + clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flexibility_score(flexibility_rating_df, num_clusters, responses, display_clusters):\n",
    "    clusters_df = sf.get_tfidf_vector(num_clusters, responses, display_clusters)\n",
    "    \n",
    "    # create dictionary out of cluster df\n",
    "    # has clusters and their respective responses\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "    \n",
    "    flex_df_cleaned = flexibility_rating_df[flexibility_rating_df.response_processed != '']\n",
    "    participants = get_id_list(flex_df_cleaned)\n",
    "    participants_responses_list = list(zip(flex_df_cleaned.id, flex_df_cleaned.response_processed))\n",
    "    \n",
    "    # get dictionary of each participants responses\n",
    "    participants_responses_dict = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_responses_dict[participants_responses_list[index][0]].append(participants_responses_list[index][1])\n",
    "        \n",
    "    # get dictionary of responses and their respective dictionary\n",
    "    responses_cluster_rep = {}\n",
    "    \n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            responses_cluster_rep[phrase] = key\n",
    "            \n",
    "    # get dictionary of participants and clusters their responses existed in\n",
    "    participants_clusters_apperance = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_clusters_apperance[participants_responses_list[index][0]].append(responses_cluster_rep[participants_responses_list[index][1]])\n",
    "        \n",
    "    # get dic of number of clusters a participants responses are in\n",
    "    \n",
    "    participants_clusters_seen = {k: [] for k in participants}\n",
    "    \n",
    "    for participant in participants_clusters_seen:\n",
    "        responses_set = set(participants_clusters_apperance[participant])\n",
    "        participants_clusters_seen[participant] = len(responses_set)\n",
    "    \n",
    "#     print(clusters)\n",
    "#     print()\n",
    "#     print(participants_responses_list)\n",
    "#     print()\n",
    "#     print(participants_responses_dict)\n",
    "#     print()\n",
    "#     print(responses_cluster_rep)\n",
    "#     print()\n",
    "#     print(participants_clusters_apperance)\n",
    "#     print()\n",
    "#     print(participants_clusters_seen)\n",
    "    \n",
    "    # create flexiblity df\n",
    "    flexibility_df = pd.DataFrame(participants_clusters_seen.items(), columns=['id', 'flexibility'])\n",
    "    return flexibility_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the flexiblity score using tfidf and clustering\n",
    "def get_flexibility_tfidf_scikit_learn_clustering(df, stopwords_list, num_clusters, join_list, display_clusters):\n",
    "    # get cleaned df\n",
    "    flexibility_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    # get phrases into a list\n",
    "    responses = flexibility_rating_df['response_processed'].tolist()\n",
    "                \n",
    "    # add flexibility df\n",
    "    flexibility_rating_df = get_flexibility_score(flexibility_rating_df, num_clusters, responses, display_clusters)\n",
    "        \n",
    "    return flexibility_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Method Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print flexibility results for human rater and method\n",
    "def print_flexibility_scores(data_dict, num_clusters):\n",
    "    # store the flexibility result dataframes for all prompts\n",
    "    flexibility_df_list = []\n",
    "    # list of the keys in the data dictionary passed in\n",
    "    data_keys = list(data_dict.keys())\n",
    "    for data in data_keys:\n",
    "        # get list of id\n",
    "        id_list = sf.get_id_list(data_dict[data])\n",
    "        participants_clusters_seen = []\n",
    "        # find the unique instance in each partipants flexibility df\n",
    "        for participant in id_list:\n",
    "            # subset dataframe and count unique categories marked\n",
    "            id_df = data_dict[data][data_dict[data].id == participant]\n",
    "            flex_1_apperance = len(id_df['flexibility_1'].unique())\n",
    "            flex_2_apperance = len(id_df['flexibility_2'].unique())\n",
    "            flex_m = (flex_1_apperance + flex_2_apperance)/2\n",
    "            # store id and flexibility score as tuple\n",
    "            participants_clusters_seen.append((participant, flex_1_apperance, flex_2_apperance, flex_m))\n",
    "        # make df out of tuple\n",
    "        flexibility_df_rater = pd.DataFrame(participants_clusters_seen, columns=['id', 'flex_1', 'flex_2', 'flex_m'])\n",
    "        # get flexibility score from algo\n",
    "        flexibility_df_method = get_flexibility_tfidf_scikit_learn_clustering(data_dict[data], stopwords_edited, num_clusters, True, False)\n",
    "        # merge the dataframes and rename columnsb\n",
    "        df_cd = pd.merge(flexibility_df_rater, flexibility_df_method, how='inner', on = 'id')\n",
    "        df_cd.columns = [['id','flex_1', 'flex_2', \"flex_m\",'flex_method']]\n",
    "        flexibility_df_list.append(df_cd)\n",
    "     \n",
    "    # return the df with human and algo flexibility scores\n",
    "    return flexibility_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out method results meaned, rerun x times\n",
    "def print_flexibility_scores_avg(data_dict, num_clusters, reruns):\n",
    "    # store the flexibility result dataframes for all prompts\n",
    "    flexibility_df_list = []\n",
    "    # list of the keys in the data dictionary passed in\n",
    "    data_keys = list(data_dict.keys())\n",
    "    for data in data_keys:\n",
    "        # get list of id\n",
    "        id_list = sf.get_id_list(data_dict[data])\n",
    "        participants_clusters_seen = []\n",
    "        # find the unique instance in each partipants flexibility df\n",
    "        for participant in id_list:\n",
    "            # subset dataframe and count unique categories marked\n",
    "            id_df = data_dict[data][data_dict[data].id == participant]\n",
    "            flex_1_apperance = len(id_df['flexibility_1'].unique())\n",
    "            flex_2_apperance = len(id_df['flexibility_2'].unique())\n",
    "            flex_m = (flex_1_apperance + flex_2_apperance)/2\n",
    "            # store id and flexibility score as tuple\n",
    "            participants_clusters_seen.append((participant, flex_1_apperance, flex_2_apperance, flex_m))\n",
    "        # make df out of tuple\n",
    "        df_cd = pd.DataFrame(participants_clusters_seen, columns=['id', 'flex_1', 'flex_2', 'flex_m'])\n",
    "        # rerun algo to take the average of the results\n",
    "        for y in range(reruns):\n",
    "            flexibility_df_method = get_flexibility_tfidf_scikit_learn_clustering(data_dict[data], stopwords_edited, num_clusters, True, False)\n",
    "            # merge the dataframes\n",
    "            df_cd = pd.merge(df_cd, flexibility_df_method, how='inner', on = 'id')\n",
    "        df_cd['flex_method_avg'] = df_cd.iloc[:,4:8].mean(axis=1)\n",
    "        # rename columns\n",
    "        df_cd = df_cd[['id','flex_1', 'flex_2', 'flex_m','flex_method_avg']]\n",
    "        flexibility_df_list.append(df_cd)\n",
    "        \n",
    "    # return the df with human and algo flexibility scores        \n",
    "    return flexibility_df_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Flexibility Results to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "underscore = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the flexibility results\n",
    "def write_flexibility_results(data_dict, flex_results_list, date):\n",
    "    # get list of prompts from the data_dict\n",
    "    data_keys = list(data_dict.keys())\n",
    "    # iterate through the results list, write out the corresponding flexibility table\n",
    "    for i in range(len(data_keys)):\n",
    "        flex_results_list[i].to_csv(\"flexibility_results_\" + date + underscore + data_keys[i] + \".csv\", encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser\n",
    "import glob\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the official novelty results\n",
    "flexiblity_dict = {}\n",
    "for filename in glob.glob(cwd + '/..//data/flexibility/official/official_csvs/*.csv'):\n",
    "    flexiblity_dict[filename[107:-4]] = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['autdata_flex_results_box',\n",
       " 'autdata_flex_results_brick',\n",
       " 'autdata_flex_results_chair',\n",
       " 'autdata_flex_results_cup',\n",
       " 'autdata_flex_results_key',\n",
       " 'autdata_flex_results_pencil',\n",
       " 'autdata_flex_results_rope',\n",
       " 'autdata_flex_results_shoe']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flexiblity_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[      id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      3      3    3.0           3\n",
       " 1   1093      2      2    2.0           2\n",
       " 2   1094      2      2    2.0           2\n",
       " 3   1102      3      3    3.0           2\n",
       " 4   1104      1      1    1.0           2\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 84  1599      1      1    1.0           3\n",
       " 85  1603      2      2    2.0           3\n",
       " 86  1610      2      2    2.0           3\n",
       " 87  1614      2      2    2.0           2\n",
       " 88  1621      1      1    1.0           2\n",
       " \n",
       " [89 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      3      3    3.0           2\n",
       " 1   1093      3      3    3.0           5\n",
       " 2   1094      1      1    1.0           5\n",
       " 3   1102      2      2    2.0           2\n",
       " 4   1104      1      1    1.0           3\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 84  1603      3      3    3.0           3\n",
       " 85  1610      2      2    2.0           5\n",
       " 86  1614      2      2    2.0           2\n",
       " 87  1621      3      3    3.0           5\n",
       " 88  1622      4      4    4.0           3\n",
       " \n",
       " [89 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      4      4    4.0           3\n",
       " 1   1093      1      1    1.0           3\n",
       " 2   1094      3      3    3.0           3\n",
       " 3   1102      3      3    3.0           2\n",
       " 4   1104      2      2    2.0           2\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 85  1603      2      2    2.0           3\n",
       " 86  1610      2      2    2.0           4\n",
       " 87  1614      1      1    1.0           3\n",
       " 88  1621      1      1    1.0           3\n",
       " 89  1622      3      3    3.0           2\n",
       " \n",
       " [90 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      3      3    3.0           5\n",
       " 1   1093      1      1    1.0           3\n",
       " 2   1094      1      1    1.0           4\n",
       " 3   1102      3      3    3.0           3\n",
       " 4   1104      2      2    2.0           2\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 84  1603      3      3    3.0           3\n",
       " 85  1610      2      2    2.0           4\n",
       " 86  1614      2      2    2.0           3\n",
       " 87  1621      1      1    1.0           3\n",
       " 88  1622      3      3    3.0           2\n",
       " \n",
       " [89 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      2      2    2.0           4\n",
       " 1   1093      3      3    3.0           2\n",
       " 2   1094      1      1    1.0           2\n",
       " 3   1102      2      2    2.0           2\n",
       " 4   1104      2      2    2.0           3\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 85  1603      2      2    2.0           3\n",
       " 86  1610      1      1    1.0           4\n",
       " 87  1614      2      2    2.0           5\n",
       " 88  1621      1      1    1.0           4\n",
       " 89  1622      3      3    3.0           2\n",
       " \n",
       " [90 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      4      4    4.0           2\n",
       " 1   1093      2      2    2.0           3\n",
       " 2   1094      1      1    1.0           2\n",
       " 3   1102      2      2    2.0           4\n",
       " 4   1104      3      3    3.0           3\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 85  1603      2      2    2.0           2\n",
       " 86  1610      2      2    2.0           4\n",
       " 87  1614      2      2    2.0           4\n",
       " 88  1621      2      2    2.0           1\n",
       " 89  1622      4      4    4.0           2\n",
       " \n",
       " [90 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      4      4    4.0           3\n",
       " 1   1093      3      3    3.0           3\n",
       " 2   1094      3      3    3.0           3\n",
       " 3   1102      2      2    2.0           4\n",
       " 4   1104      2      2    2.0           3\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 85  1603      3      3    3.0           1\n",
       " 86  1610      1      1    1.0           3\n",
       " 87  1614      2      2    2.0           3\n",
       " 88  1621      2      2    2.0           2\n",
       " 89  1622      4      4    4.0           3\n",
       " \n",
       " [90 rows x 5 columns],\n",
       "       id flex_1 flex_2 flex_m flex_method\n",
       " 0   1087      3      3    3.0           3\n",
       " 1   1093      3      3    3.0           2\n",
       " 2   1094      3      3    3.0           2\n",
       " 3   1102      3      3    3.0           6\n",
       " 4   1104      3      3    3.0           2\n",
       " ..   ...    ...    ...    ...         ...\n",
       " 85  1603      2      2    2.0           2\n",
       " 86  1610      3      3    3.0           2\n",
       " 87  1614      1      1    1.0           1\n",
       " 88  1621      2      2    2.0           2\n",
       " 89  1622      4      4    4.0           2\n",
       " \n",
       " [90 rows x 5 columns]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_flexibility_scores(flexiblity_dict, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    category                                          responses\n",
      "0          0                                       [decorative]\n",
      "1          1                                           [return]\n",
      "2          2  [storage, storage, functional permanent storag...\n",
      "3          3  [stand, stand, stand, stand reach, stand reach...\n",
      "4          4  [store, umbrella, catch bunny, standing, putti...\n",
      "5          5  [space ship, ship, ship, packaging ship, conta...\n",
      "6          6  [sit, sit, sit, turned upside sit, sit, sit in...\n",
      "7          7  [package, shipping, mail, shipping package, sh...\n",
      "8          8  [build fort, building, fort, fort, build, buil...\n",
      "9          9  [costume, halloween costume, halloween costume...\n",
      "10        10  [art, art craft, art craft, craft, art craft, ...\n",
      "11        11  [folded flattened support device, support, sup...\n",
      "12        12  [making play house, house, cat house, help hou...\n",
      "13        13  [sleep, someone head, cover rain, line floor, ...\n",
      "14        14  [play, write stuff, home duck, carrying case c...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>flexibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1093</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1603</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1610</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1614</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1621</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  flexibility\n",
       "0   1087            3\n",
       "1   1093            2\n",
       "2   1094            2\n",
       "3   1102            2\n",
       "4   1104            2\n",
       "..   ...          ...\n",
       "84  1599            3\n",
       "85  1603            3\n",
       "86  1610            3\n",
       "87  1614            2\n",
       "88  1621            2\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_flexibility_tfidf_scikit_learn_clustering(flexiblity_dict['autdata_flex_results_box'], sf.stopwords_edited, 15, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
