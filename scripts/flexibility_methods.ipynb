{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flexibility Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Flexibility Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "import shared_functions as sf\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flexibility Algo \n",
    "### tf-idf scikit-learn + clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flexibility_score(flexibility_rating_df, num_clusters, responses, display_clusters):\n",
    "    clusters_df = sf.get_tfidf_vector(num_clusters, responses, display_clusters)\n",
    "    \n",
    "    # create dictionary out of cluster df\n",
    "    # has clusters and their respective responses\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "    \n",
    "    flex_df_cleaned = flexibility_rating_df[flexibility_rating_df.response_processed != '']\n",
    "    participants = get_id_list(flex_df_cleaned)\n",
    "    participants_responses_list = list(zip(flex_df_cleaned.id, flex_df_cleaned.response_processed))\n",
    "    \n",
    "    # get dictionary of each participants responses\n",
    "    participants_responses_dict = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_responses_dict[participants_responses_list[index][0]].append(participants_responses_list[index][1])\n",
    "        \n",
    "    # get dictionary of responses and their respective dictionary\n",
    "    responses_cluster_rep = {}\n",
    "    \n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            responses_cluster_rep[phrase] = key\n",
    "            \n",
    "    # get dictionary of participants and clusters their responses existed in\n",
    "    participants_clusters_apperance = {k: [] for k in participants}\n",
    "    \n",
    "    for index in range(len(participants_responses_list)):\n",
    "        participants_clusters_apperance[participants_responses_list[index][0]].append(responses_cluster_rep[participants_responses_list[index][1]])\n",
    "        \n",
    "    # get dic of number of clusters a participants responses are in\n",
    "    \n",
    "    participants_clusters_seen = {k: [] for k in participants}\n",
    "    \n",
    "    for participant in participants_clusters_seen:\n",
    "        responses_set = set(participants_clusters_apperance[participant])\n",
    "        participants_clusters_seen[participant] = len(responses_set)\n",
    "    \n",
    "#     print(clusters)\n",
    "#     print()\n",
    "#     print(participants_responses_list)\n",
    "#     print()\n",
    "#     print(participants_responses_dict)\n",
    "#     print()\n",
    "#     print(responses_cluster_rep)\n",
    "#     print()\n",
    "#     print(participants_clusters_apperance)\n",
    "#     print()\n",
    "#     print(participants_clusters_seen)\n",
    "    \n",
    "    # create flexiblity df\n",
    "    flexibility_df = pd.DataFrame(participants_clusters_seen.items(), columns=['id', 'flexibility'])\n",
    "    return flexibility_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the flexiblity score using tfidf and clustering\n",
    "def get_flexibility_tfidf_scikit_learn_clustering(df, stopwords_list, num_clusters, join_list, display_clusters):\n",
    "    # get cleaned df\n",
    "    flexibility_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    # get phrases into a list\n",
    "    responses = flexibility_rating_df['response_processed'].tolist()\n",
    "                \n",
    "    # add flexibility df\n",
    "    flexibility_rating_df = get_flexibility_score(flexibility_rating_df, num_clusters, responses, display_clusters)\n",
    "        \n",
    "    return flexibility_rating_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Method Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print flexibility results for human rater and method\n",
    "def print_flexibility_scores(data_dict, num_clusters):\n",
    "    # store the flexibility result dataframes for all prompts\n",
    "    flexibility_df_list = []\n",
    "    # list of the keys in the data dictionary passed in\n",
    "    data_keys = list(data_dict.keys())\n",
    "    for data in data_keys:\n",
    "        # get list of id\n",
    "        id_list = sf.get_id_list(data_dict[data])\n",
    "        participants_clusters_seen = []\n",
    "        # find the unique instance in each partipants flexibility df\n",
    "        for participant in id_list:\n",
    "            # subset dataframe and count unique categories marked\n",
    "            id_df = data_dict[data][data_dict[data].id == participant]\n",
    "            flex_1_apperance = len(id_df['flexibility_1'].unique())\n",
    "            flex_2_apperance = len(id_df['flexibility_2'].unique())\n",
    "            # store id and flexibility score as tuple\n",
    "            participants_clusters_seen.append((participant, flex_1_apperance, flex_2_apperance))\n",
    "        # make df out of tuple\n",
    "        flexibility_df_rater = pd.DataFrame(participants_clusters_seen, columns=['id', 'flex_1', 'flex_2'])\n",
    "        # get flexibility score from algo\n",
    "        flexibility_df_method = get_flexibility_tfidf_scikit_learn_clustering(data_dict[data], stopwords_edited, num_clusters, True, False)\n",
    "        # merge the dataframes and rename columnsb\n",
    "        df_cd = pd.merge(flexibility_df_rater, flexibility_df_method, how='inner', on = 'id')\n",
    "        df_cd.columns = [['id','flex_1', 'flex_2','flex_method']]\n",
    "        flexibility_df_list.append(df_cd)\n",
    "     \n",
    "    # return the df with human and algo flexibility scores\n",
    "    return flexibility_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out method results meaned, rerun x times\n",
    "def print_flexibility_scores_avg(data_dict, num_clusters, reruns):\n",
    "    # store the flexibility result dataframes for all prompts\n",
    "    flexibility_df_list = []\n",
    "    # list of the keys in the data dictionary passed in\n",
    "    data_keys = list(data_dict.keys())\n",
    "    for data in data_keys:\n",
    "        # get list of id\n",
    "        id_list = sf.get_id_list(data_dict[data])\n",
    "        participants_clusters_seen = []\n",
    "        # find the unique instance in each partipants flexibility df\n",
    "        for participant in id_list:\n",
    "            # subset dataframe and count unique categories marked\n",
    "            id_df = data_dict[data][data_dict[data].id == participant]\n",
    "            flex_1_apperance = len(id_df['flexibility_1'].unique())\n",
    "            flex_2_apperance = len(id_df['flexibility_2'].unique())\n",
    "            # store id and flexibility score as tuple\n",
    "            participants_clusters_seen.append((participant, flex_1_apperance, flex_2_apperance))\n",
    "        # make df out of tuple\n",
    "        df_cd = pd.DataFrame(participants_clusters_seen, columns=['id', 'flex_1', 'flex_2'])\n",
    "        # rerun algo to take the average of the results\n",
    "        for y in range(reruns):\n",
    "            flexibility_df_method = get_flexibility_tfidf_scikit_learn_clustering(data_dict[data], stopwords_edited, num_clusters, True, False)\n",
    "            # merge the dataframes\n",
    "            df_cd = pd.merge(df_cd, flexibility_df_method, how='inner', on = 'id')\n",
    "        df_cd['flex_method_avg'] = df_cd.iloc[:,3:7].mean(axis=1)\n",
    "        # rename columns\n",
    "        df_cd = df_cd[['id','flex_1', 'flex_2','flex_method_avg']]\n",
    "        flexibility_df_list.append(df_cd)\n",
    "        \n",
    "    # return the df with human and algo flexibility scores        \n",
    "    return flexibility_df_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the Flexibility Results to CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "underscore = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the flexibility results\n",
    "def write_flexibility_results(data_dict, flex_results_list, date):\n",
    "    # get list of prompts from the data_dict\n",
    "    data_keys = list(data_dict.keys())\n",
    "    # iterate through the results list, write out the corresponding flexibility table\n",
    "    for i in range(len(data_keys)):\n",
    "        flex_results_list[i].to_csv(\"flexibility_results_\" + date + underscore + data_keys[i] + \".csv\", encoding = 'utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
