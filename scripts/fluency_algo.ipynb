{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fluency Algo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Fluency Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "from functools import reduce\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.util import ngrams\n",
    "from nltk import ngrams, FreqDist\n",
    "from nltk.lm import NgramCounter\n",
    "import string\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put Data from Excel Sheet into Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual df's for each sheet\n",
    "\n",
    "# when on pc\n",
    "data_official_cup = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_cup_semdis.csv\")\n",
    "data_official_key = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_key_semdis.csv\")\n",
    "data_official_rope = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_rope_semdis.csv\")\n",
    "data_official_brick = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_brick_semdis.csv\")\n",
    "data_official_chair = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_chair_semdis.csv\")\n",
    "data_official_pencil = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_pencil_semdis.csv\")\n",
    "data_official_shoe = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_shoe_semdis.csv\")\n",
    "data_official_box = pd.read_csv(\"C:/Users/jhec8/Documents/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_box_semdis.csv\")\n",
    "\n",
    "# when on mac\n",
    "# data_official_cup = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_cup_semdis.csv\")\n",
    "# data_official_key = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_key_semdis.csv\")\n",
    "# data_official_rope = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_rope_semdis.csv\")\n",
    "# data_official_brick = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_brick_semdis.csv\")\n",
    "# data_official_chair = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_chair_semdis.csv\")\n",
    "# data_official_pencil = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_pencil_semdis.csv\")\n",
    "# data_official_shoe = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_shoe_semdis.csv\")\n",
    "# data_official_box = pd.read_csv(\"/Users/johnhenrycruz/Desktop/Northwestern_SROP/AUT-Scoring/data/novelty/official/semdis/autdata_official_box_semdis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk corpus stop words\n",
    "stopwords_nltk = stopwords.words('english')\n",
    "# spacy stop words\n",
    "stopwords_spacy = STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_edited = list(stopwords_spacy)\n",
    "stopwords_edited.append(\"thing\")\n",
    "stopwords_edited.append(\"things\")\n",
    "stopwords_edited.append(\"use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to clean the responses\n",
    "def process_text(text, stopwords_list, remove_sw, join_list):\n",
    "    # tokenize text, lemmanize words, removing punctuation, remove stop words, lowercase all words\n",
    "\n",
    "    # hardcorded for special situations\n",
    "    text = re.sub(\"wedging\",\"wedge\", text)\n",
    "    text = re.sub(\"exersizing\",\"exercising\", text)\n",
    "    text = re.sub(\"thrown\",\"throw\", text)\n",
    "    \n",
    "    text = re.sub(\"/|-\",\" \", text)\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    if remove_sw:\n",
    "        tokens = [word for word in tokens if word not in stopwords_list]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "#         stemmer = PorterStemmer()\n",
    "#         tokens = [stemmer.stem(t) for t in tokens]\n",
    "\n",
    "    if join_list:\n",
    "        tokens = ' '.join(tokens)\n",
    " \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to get a list of participants\n",
    "def get_id_list(df):\n",
    "    id_list = df['id'].unique()\n",
    "    id_list = sorted(id_list)\n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to add a new column\n",
    "# new column are cleaned responses\n",
    "def get_cleaned_responses(df, stopwords_list, remove_sw, join_list):\n",
    "    # id_df = df[df.id == id]\n",
    "    df_processed = df.copy(deep=True)\n",
    "    responses = df['response'].tolist()\n",
    "\n",
    "    # make list of processed responses\n",
    "    for response in range(len(responses)):\n",
    "        responses[response] = process_text(responses[response], stopwords_list, remove_sw, join_list)\n",
    "\n",
    "    # add list as column in df\n",
    "    df_processed['response_processed'] = responses\n",
    "\n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluency Algo 1\n",
    "### counting rows belonging to a participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fluency_score(fluency_rating_df):\n",
    "    # get id list\n",
    "    id_list = get_id_list(fluency_rating_df)\n",
    "    participants_fluency = {k: 0 for k in id_list}\n",
    "    \n",
    "    for participant in id_list:\n",
    "        temp_df = fluency_rating_df.loc[fluency_rating_df['id'] == participant]\n",
    "        participants_fluency[participant] = len(temp_df.index)\n",
    "        \n",
    "    fluency_score_df = pd.DataFrame(participants_fluency.items(), columns=['id', 'fluency'])\n",
    "    \n",
    "    return fluency_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fluency(df, stopwords_list, remove_sw, join_list):\n",
    "    fluency_rating_df = get_cleaned_responses(df, stopwords_list, remove_sw, join_list)\n",
    "    responses_split = fluency_rating_df['response_processed'].tolist()\n",
    "    responses_split = [word for word in responses_split if word != '']\n",
    "    fluency_rating_df = fluency_rating_df[fluency_rating_df.astype(str)['response_processed'] != '']\n",
    "    \n",
    "    \n",
    "                \n",
    "    # add fleucny df\n",
    "    fluency_score_df = get_fluency_score(fluency_rating_df)\n",
    "        \n",
    "    return fluency_score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fluency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1087</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1093</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1094</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1104</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1599</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1603</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1610</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1614</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1621</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  fluency\n",
       "0   1087        4\n",
       "1   1093        8\n",
       "2   1094        4\n",
       "3   1102        7\n",
       "4   1104        2\n",
       "..   ...      ...\n",
       "84  1599        3\n",
       "85  1603        5\n",
       "86  1610        7\n",
       "87  1614        3\n",
       "88  1621        4\n",
       "\n",
       "[89 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_fluency(data_official_box, stopwords_edited, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Algo Results with Human Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_list = ['box', 'brick', 'chair', 'cup', 'key', 'pencil', 'rope', 'shoe']\n",
    "data_list = [data_official_box, data_official_brick, data_official_chair, data_official_cup, data_official_key, data_official_pencil, data_official_rope, data_official_shoe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the Method Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fluency_scores():\n",
    "    fluency_results_list = []\n",
    "    for i in range(len(prompts_list)):\n",
    "        fluency_results_list.append(get_fluency(data_list[i], stopwords_edited, True, True))\n",
    "        \n",
    "    return fluency_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flex_results_list = save_fluency_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out the flexibility results\n",
    "def write_fluency_results(flex_results_list):\n",
    "    writer = pd.ExcelWriter('fluency_methods_results_071421.xlsx', engine='xlsxwriter')\n",
    "    workbook = writer.book\n",
    "    \n",
    "    for i in range(len(prompts_list)):\n",
    "        flex_results_list[i].to_excel(writer, sheet_name = prompts_list[i], startrow = 0, startcol = 0, index = False)\n",
    "        \n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_fluency_results(flex_results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo Design Brainstorming:\n",
    "\n",
    "To Do List\n",
    "- [ ] brainstorm strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
