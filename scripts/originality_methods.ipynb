{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Originality Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to Automate Originality Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import re\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "from nltk.cluster.kmeans import KMeansClusterer\n",
    "\n",
    "import shared_functions as sf\n",
    "from shared_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Originality Algo \n",
    "### Counter Vectorizer + clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate originality score for a phrase based on number of responses in a cluster\n",
    "# calculate the rarity of a phrase\n",
    "def get_clustered_originality_score(originality_rating_df, num_clusters, responses, display_clusters):\n",
    "    # get cluster df\n",
    "    clusters_df = sf.get_counts_vector(num_clusters, responses, display_clusters)\n",
    "    # create dictionary out of cluster df\n",
    "    clusters = dict(zip(clusters_df.category, clusters_df.responses))\n",
    "        \n",
    "    # initialize empty dictionary to store the score for a category\n",
    "    clusters_scores = dict.fromkeys(clusters)\n",
    "    \n",
    "    # initialize empty dictionary to store \n",
    "    # will store 0 or 1, 1 if only 1 response in cluster\n",
    "    clusters_rarity = dict.fromkeys(clusters)\n",
    "    \n",
    "    # get the average cosine distance for a cluster\n",
    "    for key in clusters:\n",
    "        score = 1.0\n",
    "        score = score - (len(clusters[key])/len(originality_rating_df.index))\n",
    "        clusters_scores[key] = score\n",
    "        if (len(clusters[key]) == 1):\n",
    "            clusters_rarity[key] = 1\n",
    "        else:\n",
    "            clusters_rarity[key] = 0\n",
    "        \n",
    "    # create dictionary to store a phrase and its new originality score \n",
    "    # new score is the average of the responses in one cluster\n",
    "    phrase_scores_dict = {}\n",
    "    # create dictionary to store a phrase and its rarity \n",
    "    # will be 0 or 1, 1 if only response in that cluster\n",
    "    phrase_rarity_dict = {}\n",
    "    for key in clusters:\n",
    "        for phrase in clusters[key]:\n",
    "            phrase_scores_dict[phrase] = clusters_scores[key]\n",
    "            phrase_rarity_dict[phrase] = clusters_rarity[key]\n",
    "            \n",
    "    # make a list that matches the one in the current dataframe\n",
    "    # return list to be added to dataframe\n",
    "    df_phrases_scores_list = [] \n",
    "    # make a list that matches the one in the current dataframe\n",
    "    # return list to be added to dataframe\n",
    "    df_phrases_rarity_list = []\n",
    "    for phrase in originality_rating_df['response_processed'].tolist():\n",
    "        df_phrases_scores_list.append(phrase_scores_dict[phrase])\n",
    "        df_phrases_rarity_list.append(phrase_rarity_dict[phrase])\n",
    "                    \n",
    "    # return the two parallel list of the inverse mapping of the cluster frequency\n",
    "    # and the rarity marking (1 or 0)\n",
    "    return (df_phrases_scores_list, df_phrases_rarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df of each participants originality count score, the amount of \n",
    "def get_originality_score_df(originality_df):\n",
    "    # get id list and create empty dict\n",
    "    id_list = get_id_list(originality_df)\n",
    "    participants_originality = {k: 0 for k in id_list}\n",
    "    # add the number of unique responses aka clusters with only 1 response\n",
    "    for participant in id_list:\n",
    "        id_df = originality_df[originality_df.id == participant]\n",
    "        participants_originality[participant] = id_df['originality'].sum()\n",
    "    \n",
    "    # return counts df by participant\n",
    "    return pd.DataFrame(participants_originality.items(), columns=['id', 'originality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the originality freq and counts for a response and participant respectively\n",
    "def get_originality_count_vectorizer(df, stopwords_list, num_clusters, join_list, display_clusters):\n",
    "    # clean the dataframe\n",
    "    originality_rating_df = sf.get_cleaned_responses_df(df, stopwords_list, join_list)\n",
    "    responses = originality_rating_df['response_processed'].tolist()\n",
    "            \n",
    "    originality_results = get_clustered_originality_score(originality_rating_df, num_clusters, responses, display_clusters)\n",
    "    # add frequency column to results df\n",
    "    originality_rating_df['cluster_freq'] = originality_results[0]\n",
    "    # add 1/0 column to show if that phrase was by itself in a cluster\n",
    "    originality_rating_df['originality'] = originality_results[1]\n",
    "    \n",
    "    # add the transformed values of the cluster frequency as a column\n",
    "    originality_rating_df['freq'] = (1 - originality_rating_df['cluster_freq'])\n",
    "    originality_rating_df['t_freq'] = (.05/(.05 + originality_rating_df['freq']))**2\n",
    "    \n",
    "    # get the original phrases counts df\n",
    "    originality_scores = get_originality_score_df(originality_rating_df)\n",
    "\n",
    "    # return tuple of freq and count results respectively\n",
    "    return (originality_rating_df, originality_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect the Method Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate originality scores from method\n",
    "def get_originality_scores(data_dict, num_clusters):\n",
    "    # list to store the originality results\n",
    "    results_list = []\n",
    "    # list of the keys in the data dictionary passed in\n",
    "    data_keys = list(data_dict.keys())\n",
    "    for data in data_keys:\n",
    "        # get originality results for each dataset\n",
    "        results = get_originality_count_vectorizer(data_dict[data], sf.stopwords_edited, num_clusters, True, False)\n",
    "        # add originality results to a list\n",
    "        results_list.append(results)\n",
    "        \n",
    "    # return list\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Originality Results into CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "underscore = \"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write originality freq results into csvs\n",
    "def write_originality_results_freq(data_dict, results, date):\n",
    "    # get list of prompts from the data_dict\n",
    "    data_keys = list(data_dict.keys())\n",
    "    # iterate through the results list, write out the corresponding freqs table\n",
    "    for i in range(len(data_keys)):\n",
    "        results[i][0].to_csv(\"originality_results_\" + date + underscore + \"freqs\" + underscore + data_keys[i] + \".csv\", encoding = 'utf-8', index=False)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write originality counts results into csvs\n",
    "def write_originality_results_counts(data_dict, results, date):\n",
    "    # get list of prompts from the data_dict\n",
    "    data_keys = list(data_dict.keys())\n",
    "    # iterate through the results list, write out the corresponding counts table\n",
    "    for i in range(len(data_keys)):\n",
    "        results[i][1].to_csv(\"originality_results_\" + date + underscore + \"counts\" + underscore + data_keys[i] + \".csv\", encoding = 'utf-8', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4fb9038e648b520597eaf423817a5ee4bf2adb29cdca822101c12482799b056"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
